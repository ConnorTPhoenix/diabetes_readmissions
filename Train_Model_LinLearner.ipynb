{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe0425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker==1.72.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "912d1c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import relevant libraries\n",
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import time\n",
    "import json\n",
    "import sagemaker.amazon.common as smac\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "## Defin role, region, session, and default s3 bucket ##\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4173ec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in processed datasets ##\n",
    "X_sparse = scipy.sparse.load_npz('./readmissions_X.npz')\n",
    "y_sparse = scipy.sparse.load_npz('./readmissions_y.npz')\n",
    "X = pd.DataFrame(np.array(X_sparse.todense()))\n",
    "y = pd.DataFrame(np.array(y_sparse.todense()).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33bff156",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create train/test/validation sets ##\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa5385",
   "metadata": {},
   "source": [
    "#### Build LinearLearner Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aa19c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"readmissions/linreg\"\n",
    "data_dir = './data/'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8182773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save test set to local data directory ##\n",
    "pd.DataFrame(X_test).to_csv(os.path.join(data_dir, 'test.csv'), header=False, index=False)\n",
    "\n",
    "## Upload test set from local directory to s3 bucket ##\n",
    "test_location = session.upload_data(os.path.join(data_dir, 'test.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75d5d685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded training data location: s3://sagemaker-us-east-1-345989147144/readmissions/linreg/train/recordio-pb-data\n",
      "uploaded validation data location: s3://sagemaker-us-east-1-345989147144/readmissions/linreg/val/recordio-pb-data\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import sagemaker.amazon.common as smac\n",
    "\n",
    "buf = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buf, X_train.values.astype(\"float32\"), y_train.values[:,0].astype(\"float32\"))\n",
    "buf.seek(0)\n",
    "\n",
    "key = \"recordio-pb-data\"\n",
    "boto3.resource(\"s3\").Bucket(bucket).Object(os.path.join(prefix, \"train\", key)).upload_fileobj(buf)\n",
    "s3_train_data = f\"s3://{bucket}/{prefix}/train/{key}\"\n",
    "print(f\"uploaded training data location: {s3_train_data}\")\n",
    "\n",
    "buf = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buf, X_val.values.astype(\"float32\"), y_val.values[:,0].astype(\"float32\"))\n",
    "buf.seek(0)\n",
    "\n",
    "key = \"recordio-pb-data\"\n",
    "boto3.resource(\"s3\").Bucket(bucket).Object(os.path.join(prefix, \"val\", key)).upload_fileobj(buf)\n",
    "s3_val_data = f\"s3://{bucket}/{prefix}/val/{key}\"\n",
    "print(f\"uploaded validation data location: {s3_val_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f6aede2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "## get image and define Linear Learner estimator object ##\n",
    "container = get_image_uri(session.boto_region_name, 'linear-learner')\n",
    "linear = sagemaker.estimator.Estimator(\n",
    "         container,\n",
    "         role,\n",
    "         train_instance_count=1,\n",
    "         train_instance_type=\"ml.c4.xlarge\",\n",
    "         output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "         sagemaker_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35254143",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set default hyperparameters ##\n",
    "linear.set_hyperparameters(feature_dim=105, predictor_type=\"binary_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "299c82b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate tuner instance and input tunable hyperparameter ranges ##\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, CategoricalParameter, HyperparameterTuner\n",
    "lin_hyperparameter_tuner = HyperparameterTuner(estimator = linear, \n",
    "                                               objective_metric_name = 'validation:binary_classification_accuracy', \n",
    "                                               objective_type = 'Maximize',\n",
    "                                               max_jobs = 20,\n",
    "                                               max_parallel_jobs = 3,\n",
    "                                               hyperparameter_ranges = {\n",
    "                                                    'wd': ContinuousParameter(0.1, 1.0),\n",
    "                                                    'l1'      : ContinuousParameter(0.1, 1.0),\n",
    "                                                    'learning_rate': ContinuousParameter(0.1, 1.0),\n",
    "                                                    'mini_batch_size': IntegerParameter(100, 5000),\n",
    "                                                    'use_bias': CategoricalParameter([True, False])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92e6573e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................................................................................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "## Point tuner object to training/validation s3 locations and fit tuner##\n",
    "lin_hyperparameter_tuner.fit({'train': s3_train_data, 'validation': s3_val_data})\n",
    "lin_hyperparameter_tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f735508f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>mini_batch_size</th>\n",
       "      <th>use_bias</th>\n",
       "      <th>wd</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.200825</td>\n",
       "      <td>0.205698</td>\n",
       "      <td>4331.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.10565</td>\n",
       "      <td>linear-learner-220104-2108-012-2611030e</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.612453</td>\n",
       "      <td>2022-01-04 21:25:03+00:00</td>\n",
       "      <td>2022-01-04 21:26:25+00:00</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         l1  learning_rate  mini_batch_size use_bias       wd  \\\n",
       "8  0.200825       0.205698           4331.0     True  0.10565   \n",
       "\n",
       "                           TrainingJobName TrainingJobStatus  \\\n",
       "8  linear-learner-220104-2108-012-2611030e         Completed   \n",
       "\n",
       "   FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
       "8             0.612453 2022-01-04 21:25:03+00:00 2022-01-04 21:26:25+00:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "8                        82.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## View Hyperparameters and performance for best job ##\n",
    "analytics = lin_hyperparameter_tuner.analytics()\n",
    "analytics_df = analytics.dataframe()\n",
    "\n",
    "best_job = lin_hyperparameter_tuner.best_training_job()\n",
    "analytics_df[analytics_df['TrainingJobName'] == best_job]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "695d6358",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-04 21:26:25 Starting - Preparing the instances for training\n",
      "2022-01-04 21:26:25 Downloading - Downloading input data\n",
      "2022-01-04 21:26:25 Training - Training image download completed. Training in progress.\n",
      "2022-01-04 21:26:25 Uploading - Uploading generated training model\n",
      "2022-01-04 21:26:25 Completed - Training job completed\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:13 INFO 140250267572032] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-input.json: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': 'auto', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false'}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:13 INFO 140250267572032] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'feature_dim': '105', 'predictor_type': 'binary_classifier', 'l1': '0.20082452777595738', '_tuning_objective_metric': 'validation:binary_classification_accuracy', 'use_bias': 'True', 'learning_rate': '0.2056981137054709', 'wd': '0.10565041525629222', 'mini_batch_size': '4331'}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:13 INFO 140250267572032] Final configuration: {'mini_batch_size': '4331', 'epochs': '15', 'feature_dim': '105', 'use_bias': 'True', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': '0.10565041525629222', 'l1': '0.20082452777595738', 'momentum': 'auto', 'learning_rate': '0.2056981137054709', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': 'validation:binary_classification_accuracy', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'binary_classifier'}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:13 WARNING 140250267572032] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:13 INFO 140250267572032] Using default worker.\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:13 INFO 140250267572032] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:13.756] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:13.793] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 46, \"num_examples\": 1, \"num_bytes\": 2026908}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:13 INFO 140250267572032] Create Store: local\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:13.887] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 92, \"num_examples\": 3, \"num_bytes\": 6080724}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:13 INFO 140250267572032] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7f8e2e74d250>\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:13 INFO 140250267572032] Scaling model computed with parameters:\n",
      " {'stdev_label': None, 'stdev_weight': \u001b[0m\n",
      "\u001b[34m[ 8.006683    2.9571438  19.808083    1.6974665   1.2818266   0.89646786\n",
      "  1.2274632   1.9461944   0.1521287   0.43335655  0.13737142  0.11330412\n",
      "  0.49898127  0.49898127  0.18993905  0.29717785  0.37652224  0.4358519\n",
      "  0.37285003  0.15404314  0.18265508  0.1215847   0.32140368  0.11429197\n",
      "  0.1050491   0.14003694  0.27745566  0.14747205  0.10856882  0.10752558\n",
      "  0.18824348  0.19673066  0.16031823  0.1338203   0.13574491  0.11396369\n",
      "  0.12930524  0.11363441  0.23910813  0.25167668  0.12065995  0.18843275\n",
      "  0.16501589  0.15709919  0.11910175  0.2121864   0.24577129  0.1215847\n",
      "  0.18245883  0.1266896   0.12461457  0.13950825  0.1129728   0.1237139\n",
      "  0.13871112  0.17645448  0.24740043  0.16077223  0.24955076  0.17828017\n",
      "  0.15188752  0.10250998  0.11062434  0.12521118  0.12219707  0.14419077\n",
      "  0.1963706   0.10752558  0.1307342   0.21070209  0.15825722  0.4649803\n",
      "  0.15164594  0.4997827   0.22516185  0.26158518  0.26283482  0.35418484\n",
      "  0.12127729  0.11461927  0.10822225  0.10250998  0.17189835  0.19161712\n",
      "  0.27266568  0.37428787  0.21672507  0.11559527  0.10717546  0.40168712\n",
      "  0.38787836  0.1050491   0.1215847   0.32048428  0.2795214   0.25559917\n",
      "  0.2457713   0.32186174  0.49923816  0.45919538  0.3104539   0.49872032\n",
      "  0.49872032  0.4187214   0.41872138]\u001b[0m\n",
      "\u001b[34m<NDArray 105 @cpu(0)>, 'mean_label': None, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[1.58089752e+01 4.36511993e+00 4.30834312e+01 1.31424618e+00\n",
      " 3.77895802e-01 2.04263836e-01 6.23489559e-01 7.40591145e+00\n",
      " 2.37050708e-02 7.49403536e-01 1.92411281e-02 1.30070038e-02\n",
      " 5.31901836e-01 4.68098223e-01 3.74817178e-02 9.78988633e-02\n",
      " 1.71015158e-01 2.54983455e-01 1.66859075e-01 2.43207868e-02\n",
      " 9.65442955e-01 1.50080808e-02 1.16986066e-01 1.32378973e-02\n",
      " 1.11598549e-02 2.00107731e-02 8.40452537e-02 2.22427454e-02\n",
      " 1.19295008e-02 1.16986074e-02 3.67890373e-02 4.03294079e-02\n",
      " 2.63988301e-02 1.82405896e-02 1.87793411e-02 1.31609328e-02\n",
      " 1.70091577e-02 1.30839683e-02 6.08789325e-02 6.79596663e-02\n",
      " 1.47771873e-02 3.68660018e-02 2.80150846e-02 2.53213271e-02\n",
      " 1.43923648e-02 4.72562164e-02 6.45732284e-02 1.50080808e-02\n",
      " 3.44801024e-02 1.63164772e-02 1.57777257e-02 1.98568460e-02\n",
      " 1.29300393e-02 1.55468322e-02 1.96259525e-02 3.21711674e-02\n",
      " 6.54968023e-02 2.65527591e-02 6.67282343e-02 3.28638479e-02\n",
      " 2.36281063e-02 1.06211035e-02 1.23912878e-02 1.59316547e-02\n",
      " 1.51620097e-02 2.12422069e-02 4.01754752e-02 1.16986074e-02\n",
      " 1.73939802e-02 4.65635322e-02 2.57061496e-02 3.16170245e-01\n",
      " 2.35511418e-02 4.85261291e-01 5.35673052e-02 7.38859400e-02\n",
      " 7.46555775e-02 1.47079200e-01 1.49311163e-02 1.33148618e-02\n",
      " 1.18525364e-02 1.06211035e-02 3.04779485e-02 3.81743982e-02\n",
      " 8.08897093e-02 8.31524730e-01 4.94112223e-02 1.35457553e-02\n",
      " 1.16216419e-02 7.97737241e-01 1.84483945e-01 1.11598549e-02\n",
      " 1.50080808e-02 1.16216421e-01 8.54306147e-02 7.02686012e-02\n",
      " 6.45732284e-02 1.17370889e-01 4.72408205e-01 3.02162707e-01\n",
      " 1.08058184e-01 4.64249969e-01 5.35750031e-01 2.26737469e-01\n",
      " 7.73262501e-01]\u001b[0m\n",
      "\u001b[34m<NDArray 105 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:13 INFO 140250267572032] nvidia-smi: took 0.056 seconds to run.\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:13 INFO 140250267572032] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:13 INFO 140250267572032] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331573.959212, \"EndTime\": 1641331573.9592438, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 17324.0, \"count\": 1, \"min\": 17324, \"max\": 17324}, \"Total Batches Seen\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Max Records Seen Between Resets\": {\"sum\": 12993.0, \"count\": 1, \"min\": 12993, \"max\": 12993}, \"Max Batches Seen Between Resets\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:14.051] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 3, \"duration\": 91, \"num_examples\": 10, \"num_bytes\": 19670508}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331574.051377, \"EndTime\": 1641331574.0516229, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.8560771066732247, \"count\": 1, \"min\": 0.8560771066732247, \"max\": 0.8560771066732247}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #quality_metric: host=algo-1, epoch=0, train binary_classification_cross_entropy_objective <loss>=0.8560771066732247\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:14.053] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 0, \"duration\": 297, \"num_examples\": 1, \"num_bytes\": 2026908}\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:14.164] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 2, \"duration\": 110, \"num_examples\": 5, \"num_bytes\": 9688536}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331574.1965606, \"EndTime\": 1641331574.1965861, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.8244574658019153, \"count\": 1, \"min\": 0.8244574658019153, \"max\": 0.8244574658019153}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #quality_metric: host=algo-1, epoch=0, validation binary_classification_cross_entropy_objective <loss>=0.8244574658019153\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=sampled_accuracy, value=0.5956429330499489\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] Saving model for epoch: 0\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] Saved checkpoint to \"/tmp/tmpihkegjg0/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #progress_metric: host=algo-1, completed 6.666666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331573.9594963, \"EndTime\": 1641331574.2067728, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 59355.0, \"count\": 1, \"min\": 59355, \"max\": 59355}, \"Total Batches Seen\": {\"sum\": 14.0, \"count\": 1, \"min\": 14, \"max\": 14}, \"Max Records Seen Between Resets\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Max Batches Seen Between Resets\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Number of Batches Since Last Reset\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #throughput_metric: host=algo-1, train throughput=169884.93999173178 records/second\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:14.280] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 5, \"duration\": 72, \"num_examples\": 10, \"num_bytes\": 19670508}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331574.2804184, \"EndTime\": 1641331574.280473, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.7374510378384835, \"count\": 1, \"min\": 0.7374510378384835, \"max\": 0.7374510378384835}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #quality_metric: host=algo-1, epoch=1, train binary_classification_cross_entropy_objective <loss>=0.7374510378384835\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:14.387] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 5, \"duration\": 105, \"num_examples\": 5, \"num_bytes\": 9688536}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331574.404828, \"EndTime\": 1641331574.404852, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.717854703708428, \"count\": 1, \"min\": 0.717854703708428, \"max\": 0.717854703708428}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #quality_metric: host=algo-1, epoch=1, validation binary_classification_cross_entropy_objective <loss>=0.717854703708428\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=sampled_accuracy, value=0.604144527098833\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] Saving model for epoch: 1\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] Saved checkpoint to \"/tmp/tmpuiqi3r_a/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #progress_metric: host=algo-1, completed 13.333333333333334 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331574.2074823, \"EndTime\": 1641331574.4109273, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 101386.0, \"count\": 1, \"min\": 101386, \"max\": 101386}, \"Total Batches Seen\": {\"sum\": 24.0, \"count\": 1, \"min\": 24, \"max\": 24}, \"Max Records Seen Between Resets\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Max Batches Seen Between Resets\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Number of Batches Since Last Reset\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #throughput_metric: host=algo-1, train throughput=206479.3046378869 records/second\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:14.489] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 7, \"duration\": 77, \"num_examples\": 10, \"num_bytes\": 19670508}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331574.489089, \"EndTime\": 1641331574.4891267, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6917608893270254, \"count\": 1, \"min\": 0.6917608893270254, \"max\": 0.6917608893270254}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #quality_metric: host=algo-1, epoch=2, train binary_classification_cross_entropy_objective <loss>=0.6917608893270254\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:14.590] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 8, \"duration\": 99, \"num_examples\": 5, \"num_bytes\": 9688536}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331574.6068373, \"EndTime\": 1641331574.606872, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6712542941012644, \"count\": 1, \"min\": 0.6712542941012644, \"max\": 0.6712542941012644}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #quality_metric: host=algo-1, epoch=2, validation binary_classification_cross_entropy_objective <loss>=0.6712542941012644\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=sampled_accuracy, value=0.6155443918462004\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] Saving model for epoch: 2\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] Saved checkpoint to \"/tmp/tmpnugxnlyy/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331574.4116151, \"EndTime\": 1641331574.6134427, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 143417.0, \"count\": 1, \"min\": 143417, \"max\": 143417}, \"Total Batches Seen\": {\"sum\": 34.0, \"count\": 1, \"min\": 34, \"max\": 34}, \"Max Records Seen Between Resets\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Max Batches Seen Between Resets\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Number of Batches Since Last Reset\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #throughput_metric: host=algo-1, train throughput=208107.51731644146 records/second\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:14.685] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 9, \"duration\": 71, \"num_examples\": 10, \"num_bytes\": 19670508}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331574.6856086, \"EndTime\": 1641331574.685653, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6732889411906893, \"count\": 1, \"min\": 0.6732889411906893, \"max\": 0.6732889411906893}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #quality_metric: host=algo-1, epoch=3, train binary_classification_cross_entropy_objective <loss>=0.6732889411906893\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:14.793] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 11, \"duration\": 106, \"num_examples\": 5, \"num_bytes\": 9688536}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331574.8103104, \"EndTime\": 1641331574.8103483, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6606660772321213, \"count\": 1, \"min\": 0.6606660772321213, \"max\": 0.6606660772321213}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #quality_metric: host=algo-1, epoch=3, validation binary_classification_cross_entropy_objective <loss>=0.6606660772321213\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=sampled_accuracy, value=0.6123562940778688\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] Saving model for epoch: 3\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] Saved checkpoint to \"/tmp/tmpp3eb_z90/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #progress_metric: host=algo-1, completed 26.666666666666668 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331574.6141715, \"EndTime\": 1641331574.816836, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 185448.0, \"count\": 1, \"min\": 185448, \"max\": 185448}, \"Total Batches Seen\": {\"sum\": 44.0, \"count\": 1, \"min\": 44, \"max\": 44}, \"Max Records Seen Between Resets\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Max Batches Seen Between Resets\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Number of Batches Since Last Reset\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #throughput_metric: host=algo-1, train throughput=207273.15328432826 records/second\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:14.923] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 11, \"duration\": 105, \"num_examples\": 10, \"num_bytes\": 19670508}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331574.9236171, \"EndTime\": 1641331574.9236703, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6657579617189705, \"count\": 1, \"min\": 0.6657579617189705, \"max\": 0.6657579617189705}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:14 INFO 140250267572032] #quality_metric: host=algo-1, epoch=4, train binary_classification_cross_entropy_objective <loss>=0.6657579617189705\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:15.072] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 14, \"duration\": 147, \"num_examples\": 5, \"num_bytes\": 9688536}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331575.0928302, \"EndTime\": 1641331575.0928786, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6561215850031096, \"count\": 1, \"min\": 0.6561215850031096, \"max\": 0.6561215850031096}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] #quality_metric: host=algo-1, epoch=4, validation binary_classification_cross_entropy_objective <loss>=0.6561215850031096\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=sampled_accuracy, value=0.6140469519853173\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] Epoch 4: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] Saving model for epoch: 4\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] Saved checkpoint to \"/tmp/tmp09e7zme2/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] #progress_metric: host=algo-1, completed 33.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331574.8175182, \"EndTime\": 1641331575.1019454, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 227479.0, \"count\": 1, \"min\": 227479, \"max\": 227479}, \"Total Batches Seen\": {\"sum\": 54.0, \"count\": 1, \"min\": 54, \"max\": 54}, \"Max Records Seen Between Resets\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Max Batches Seen Between Resets\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Number of Batches Since Last Reset\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] #throughput_metric: host=algo-1, train throughput=147702.77216809336 records/second\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:15.210] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 13, \"duration\": 107, \"num_examples\": 10, \"num_bytes\": 19670508}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331575.210652, \"EndTime\": 1641331575.2107062, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6637573727600118, \"count\": 1, \"min\": 0.6637573727600118, \"max\": 0.6637573727600118}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] #quality_metric: host=algo-1, epoch=5, train binary_classification_cross_entropy_objective <loss>=0.6637573727600118\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:15.337] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 17, \"duration\": 124, \"num_examples\": 5, \"num_bytes\": 9688536}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331575.3589718, \"EndTime\": 1641331575.3590195, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6546558331848976, \"count\": 1, \"min\": 0.6546558331848976, \"max\": 0.6546558331848976}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] #quality_metric: host=algo-1, epoch=5, validation binary_classification_cross_entropy_objective <loss>=0.6546558331848976\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] #early_stopping_criteria_metric: host=algo-1, epoch=5, criteria=sampled_accuracy, value=0.6181528354748352\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] Epoch 5: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] Saving model for epoch: 5\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] Saved checkpoint to \"/tmp/tmpc1au1yb5/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331575.102692, \"EndTime\": 1641331575.3668048, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 269510.0, \"count\": 1, \"min\": 269510, \"max\": 269510}, \"Total Batches Seen\": {\"sum\": 64.0, \"count\": 1, \"min\": 64, \"max\": 64}, \"Max Records Seen Between Resets\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Max Batches Seen Between Resets\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Number of Batches Since Last Reset\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] #throughput_metric: host=algo-1, train throughput=159054.9597641208 records/second\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:15.465] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 15, \"duration\": 97, \"num_examples\": 10, \"num_bytes\": 19670508}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331575.4651008, \"EndTime\": 1641331575.465151, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6617718785676262, \"count\": 1, \"min\": 0.6617718785676262, \"max\": 0.6617718785676262}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] #quality_metric: host=algo-1, epoch=6, train binary_classification_cross_entropy_objective <loss>=0.6617718785676262\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:15.598] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 20, \"duration\": 131, \"num_examples\": 5, \"num_bytes\": 9688536}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331575.6248507, \"EndTime\": 1641331575.6248844, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6546767069606801, \"count\": 1, \"min\": 0.6546767069606801, \"max\": 0.6546767069606801}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] #quality_metric: host=algo-1, epoch=6, validation binary_classification_cross_entropy_objective <loss>=0.6546767069606801\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] #early_stopping_criteria_metric: host=algo-1, epoch=6, criteria=sampled_accuracy, value=0.6159308279393314\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] Epoch 6: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] Saving model for epoch: 6\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] Saved checkpoint to \"/tmp/tmp7q_n4elx/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] #progress_metric: host=algo-1, completed 46.666666666666664 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331575.3671424, \"EndTime\": 1641331575.6336427, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 311541.0, \"count\": 1, \"min\": 311541, \"max\": 311541}, \"Total Batches Seen\": {\"sum\": 74.0, \"count\": 1, \"min\": 74, \"max\": 74}, \"Max Records Seen Between Resets\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Max Batches Seen Between Resets\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Number of Batches Since Last Reset\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] #throughput_metric: host=algo-1, train throughput=157641.20616934216 records/second\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:15.752] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 17, \"duration\": 117, \"num_examples\": 10, \"num_bytes\": 19670508}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331575.752604, \"EndTime\": 1641331575.7526584, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6619020004661965, \"count\": 1, \"min\": 0.6619020004661965, \"max\": 0.6619020004661965}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] #quality_metric: host=algo-1, epoch=7, train binary_classification_cross_entropy_objective <loss>=0.6619020004661965\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:15.864] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 23, \"duration\": 110, \"num_examples\": 5, \"num_bytes\": 9688536}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331575.882087, \"EndTime\": 1641331575.8821266, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6532643188912907, \"count\": 1, \"min\": 0.6532643188912907, \"max\": 0.6532643188912907}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] #quality_metric: host=algo-1, epoch=7, validation binary_classification_cross_entropy_objective <loss>=0.6532643188912907\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] #early_stopping_criteria_metric: host=algo-1, epoch=7, criteria=sampled_accuracy, value=0.6160757414742556\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] Epoch 7: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] Saving model for epoch: 7\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] Saved checkpoint to \"/tmp/tmp3sou85o_/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] #progress_metric: host=algo-1, completed 53.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331575.6345928, \"EndTime\": 1641331575.8888195, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 353572.0, \"count\": 1, \"min\": 353572, \"max\": 353572}, \"Total Batches Seen\": {\"sum\": 84.0, \"count\": 1, \"min\": 84, \"max\": 84}, \"Max Records Seen Between Resets\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Max Batches Seen Between Resets\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Number of Batches Since Last Reset\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] #throughput_metric: host=algo-1, train throughput=165226.0954874893 records/second\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:15.989] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 19, \"duration\": 99, \"num_examples\": 10, \"num_bytes\": 19670508}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331575.9895144, \"EndTime\": 1641331575.9895606, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.662446721111047, \"count\": 1, \"min\": 0.662446721111047, \"max\": 0.662446721111047}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:15 INFO 140250267572032] #quality_metric: host=algo-1, epoch=8, train binary_classification_cross_entropy_objective <loss>=0.662446721111047\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:16.116] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 26, \"duration\": 124, \"num_examples\": 5, \"num_bytes\": 9688536}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331576.1357095, \"EndTime\": 1641331576.1357632, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6531630398029176, \"count\": 1, \"min\": 0.6531630398029176, \"max\": 0.6531630398029176}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] #quality_metric: host=algo-1, epoch=8, validation binary_classification_cross_entropy_objective <loss>=0.6531630398029176\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] #early_stopping_criteria_metric: host=algo-1, epoch=8, criteria=sampled_accuracy, value=0.6145299971017312\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] Epoch 8: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] Saving model for epoch: 8\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] Saved checkpoint to \"/tmp/tmp78ifcy8z/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331575.8896155, \"EndTime\": 1641331576.143753, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 395603.0, \"count\": 1, \"min\": 395603, \"max\": 395603}, \"Total Batches Seen\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Max Records Seen Between Resets\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Max Batches Seen Between Resets\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Number of Batches Since Last Reset\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] #throughput_metric: host=algo-1, train throughput=165300.14976619542 records/second\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:16.240] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 21, \"duration\": 96, \"num_examples\": 10, \"num_bytes\": 19670508}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331576.2409499, \"EndTime\": 1641331576.241, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6628696626909683, \"count\": 1, \"min\": 0.6628696626909683, \"max\": 0.6628696626909683}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] #quality_metric: host=algo-1, epoch=9, train binary_classification_cross_entropy_objective <loss>=0.6628696626909683\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:16.365] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 29, \"duration\": 122, \"num_examples\": 5, \"num_bytes\": 9688536}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331576.390288, \"EndTime\": 1641331576.3903258, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6536778083412834, \"count\": 1, \"min\": 0.6536778083412834, \"max\": 0.6536778083412834}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] #quality_metric: host=algo-1, epoch=9, validation binary_classification_cross_entropy_objective <loss>=0.6536778083412834\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] #early_stopping_criteria_metric: host=algo-1, epoch=9, criteria=sampled_accuracy, value=0.6134672978456207\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] Epoch 9: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] Saving model for epoch: 9\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] Saved checkpoint to \"/tmp/tmptopunhku/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] #progress_metric: host=algo-1, completed 66.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331576.144056, \"EndTime\": 1641331576.3975623, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 437634.0, \"count\": 1, \"min\": 437634, \"max\": 437634}, \"Total Batches Seen\": {\"sum\": 104.0, \"count\": 1, \"min\": 104, \"max\": 104}, \"Max Records Seen Between Resets\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Max Batches Seen Between Resets\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Reset Count\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Number of Records Since Last Reset\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Number of Batches Since Last Reset\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] #throughput_metric: host=algo-1, train throughput=165705.5226378915 records/second\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:16.493] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 23, \"duration\": 95, \"num_examples\": 10, \"num_bytes\": 19670508}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331576.4937174, \"EndTime\": 1641331576.4937766, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6632669556944926, \"count\": 1, \"min\": 0.6632669556944926, \"max\": 0.6632669556944926}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] #quality_metric: host=algo-1, epoch=10, train binary_classification_cross_entropy_objective <loss>=0.6632669556944926\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:16.616] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 32, \"duration\": 121, \"num_examples\": 5, \"num_bytes\": 9688536}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331576.646198, \"EndTime\": 1641331576.6462388, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6540077673088651, \"count\": 1, \"min\": 0.6540077673088651, \"max\": 0.6540077673088651}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] #quality_metric: host=algo-1, epoch=10, validation binary_classification_cross_entropy_objective <loss>=0.6540077673088651\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] #early_stopping_criteria_metric: host=algo-1, epoch=10, criteria=sampled_accuracy, value=0.6133706888223379\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] Epoch 10: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] Saving model for epoch: 10\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] Saved checkpoint to \"/tmp/tmp39zk5anm/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] #progress_metric: host=algo-1, completed 73.33333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331576.3978791, \"EndTime\": 1641331576.6545157, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 479665.0, \"count\": 1, \"min\": 479665, \"max\": 479665}, \"Total Batches Seen\": {\"sum\": 114.0, \"count\": 1, \"min\": 114, \"max\": 114}, \"Max Records Seen Between Resets\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Max Batches Seen Between Resets\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Reset Count\": {\"sum\": 13.0, \"count\": 1, \"min\": 13, \"max\": 13}, \"Number of Records Since Last Reset\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Number of Batches Since Last Reset\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] #throughput_metric: host=algo-1, train throughput=163689.17990872668 records/second\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:16.752] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 25, \"duration\": 97, \"num_examples\": 10, \"num_bytes\": 19670508}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331576.752643, \"EndTime\": 1641331576.7526968, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.663518562278727, \"count\": 1, \"min\": 0.663518562278727, \"max\": 0.663518562278727}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] #quality_metric: host=algo-1, epoch=11, train binary_classification_cross_entropy_objective <loss>=0.663518562278727\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:16.852] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 35, \"duration\": 98, \"num_examples\": 5, \"num_bytes\": 9688536}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331576.869862, \"EndTime\": 1641331576.8698962, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6542793150835367, \"count\": 1, \"min\": 0.6542793150835367, \"max\": 0.6542793150835367}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] #quality_metric: host=algo-1, epoch=11, validation binary_classification_cross_entropy_objective <loss>=0.6542793150835367\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] #early_stopping_criteria_metric: host=algo-1, epoch=11, criteria=sampled_accuracy, value=0.6132740797990551\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] Epoch 11: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] Saving model for epoch: 11\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] Saved checkpoint to \"/tmp/tmpigb1icup/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331576.654897, \"EndTime\": 1641331576.8764558, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 521696.0, \"count\": 1, \"min\": 521696, \"max\": 521696}, \"Total Batches Seen\": {\"sum\": 124.0, \"count\": 1, \"min\": 124, \"max\": 124}, \"Max Records Seen Between Resets\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Max Batches Seen Between Resets\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Reset Count\": {\"sum\": 14.0, \"count\": 1, \"min\": 14, \"max\": 14}, \"Number of Records Since Last Reset\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Number of Batches Since Last Reset\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] #throughput_metric: host=algo-1, train throughput=189530.4403334964 records/second\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:16.956] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 27, \"duration\": 79, \"num_examples\": 10, \"num_bytes\": 19670508}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331576.9561048, \"EndTime\": 1641331576.9561508, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6637214710164447, \"count\": 1, \"min\": 0.6637214710164447, \"max\": 0.6637214710164447}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:16 INFO 140250267572032] #quality_metric: host=algo-1, epoch=12, train binary_classification_cross_entropy_objective <loss>=0.6637214710164447\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:17.084] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 38, \"duration\": 127, \"num_examples\": 5, \"num_bytes\": 9688536}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331577.1015482, \"EndTime\": 1641331577.1015794, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6542756946037822, \"count\": 1, \"min\": 0.6542756946037822, \"max\": 0.6542756946037822}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #quality_metric: host=algo-1, epoch=12, validation binary_classification_cross_entropy_objective <loss>=0.6542756946037822\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #early_stopping_criteria_metric: host=algo-1, epoch=12, criteria=sampled_accuracy, value=0.6124529031011515\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] Epoch 12: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] Saving model for epoch: 12\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] Saved checkpoint to \"/tmp/tmp7m4azzwh/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #progress_metric: host=algo-1, completed 86.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331576.8768141, \"EndTime\": 1641331577.107494, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 563727.0, \"count\": 1, \"min\": 563727, \"max\": 563727}, \"Total Batches Seen\": {\"sum\": 134.0, \"count\": 1, \"min\": 134, \"max\": 134}, \"Max Records Seen Between Resets\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Max Batches Seen Between Resets\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Reset Count\": {\"sum\": 15.0, \"count\": 1, \"min\": 15, \"max\": 15}, \"Number of Records Since Last Reset\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Number of Batches Since Last Reset\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #throughput_metric: host=algo-1, train throughput=182097.32895230205 records/second\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:17.182] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 29, \"duration\": 74, \"num_examples\": 10, \"num_bytes\": 19670508}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331577.1821513, \"EndTime\": 1641331577.1821952, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6638432688715398, \"count\": 1, \"min\": 0.6638432688715398, \"max\": 0.6638432688715398}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #quality_metric: host=algo-1, epoch=13, train binary_classification_cross_entropy_objective <loss>=0.6638432688715398\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:17.288] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 41, \"duration\": 104, \"num_examples\": 5, \"num_bytes\": 9688536}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331577.3046727, \"EndTime\": 1641331577.3047042, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6543703459735171, \"count\": 1, \"min\": 0.6543703459735171, \"max\": 0.6543703459735171}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #quality_metric: host=algo-1, epoch=13, validation binary_classification_cross_entropy_objective <loss>=0.6543703459735171\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #early_stopping_criteria_metric: host=algo-1, epoch=13, criteria=sampled_accuracy, value=0.6119698579847377\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] Epoch 13: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] Saving model for epoch: 13\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] Saved checkpoint to \"/tmp/tmp9he0kd3x/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #progress_metric: host=algo-1, completed 93.33333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331577.107787, \"EndTime\": 1641331577.3105714, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 605758.0, \"count\": 1, \"min\": 605758, \"max\": 605758}, \"Total Batches Seen\": {\"sum\": 144.0, \"count\": 1, \"min\": 144, \"max\": 144}, \"Max Records Seen Between Resets\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Max Batches Seen Between Resets\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Reset Count\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Number of Records Since Last Reset\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Number of Batches Since Last Reset\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #throughput_metric: host=algo-1, train throughput=207130.68646201602 records/second\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:17.382] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 31, \"duration\": 70, \"num_examples\": 10, \"num_bytes\": 19670508}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331577.3820555, \"EndTime\": 1641331577.3821018, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6638627855904782, \"count\": 1, \"min\": 0.6638627855904782, \"max\": 0.6638627855904782}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #quality_metric: host=algo-1, epoch=14, train binary_classification_cross_entropy_objective <loss>=0.6638627855904782\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:17.498] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 44, \"duration\": 114, \"num_examples\": 5, \"num_bytes\": 9688536}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331577.5151014, \"EndTime\": 1641331577.5151322, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6545077708939656, \"count\": 1, \"min\": 0.6545077708939656, \"max\": 0.6545077708939656}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #quality_metric: host=algo-1, epoch=14, validation binary_classification_cross_entropy_objective <loss>=0.6545077708939656\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #early_stopping_criteria_metric: host=algo-1, epoch=14, criteria=sampled_accuracy, value=0.6124045985895102\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] Epoch 14: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] Saving model for epoch: 14\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] Saved checkpoint to \"/tmp/tmpwjvxlaic/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331577.3108883, \"EndTime\": 1641331577.5217533, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 647789.0, \"count\": 1, \"min\": 647789, \"max\": 647789}, \"Total Batches Seen\": {\"sum\": 154.0, \"count\": 1, \"min\": 154, \"max\": 154}, \"Max Records Seen Between Resets\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Max Batches Seen Between Resets\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Reset Count\": {\"sum\": 17.0, \"count\": 1, \"min\": 17, \"max\": 17}, \"Number of Records Since Last Reset\": {\"sum\": 42031.0, \"count\": 1, \"min\": 42031, \"max\": 42031}, \"Number of Batches Since Last Reset\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}}}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #throughput_metric: host=algo-1, train throughput=199196.6086491776 records/second\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 WARNING 140250267572032] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 WARNING 140250267572032] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:17.623] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 47, \"duration\": 99, \"num_examples\": 5, \"num_bytes\": 9688536}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #early_stopping_criteria_metric: host=algo-1, epoch=14, criteria=sampled_accuracy, value=0.6124045985895102\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] Epoch 14: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:26:17.688] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 49, \"duration\": 43, \"num_examples\": 5, \"num_bytes\": 9688536}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #validation_score (algo-1) : ('binary_classification_cross_entropy_objective', 0.6545077708939656)\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #validation_score (algo-1) : ('binary_classification_accuracy', 0.6124529031011496)\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #validation_score (algo-1) : ('binary_f_1.000', 0.6035087719298246)\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #validation_score (algo-1) : ('precision', 0.6228070175438597)\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #validation_score (algo-1) : ('recall', 0.5853705301505129)\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #validation_score (algo-1) : ('roc_auc_score', 0.6552816431395969)\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #validation_score (algo-1) : ('binary_balanced_accuracy', 0.5)\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #validation_score (algo-1) : ('binary_log_loss', 0.7045713287604352)\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #quality_metric: host=algo-1, validation binary_classification_cross_entropy_objective <loss>=0.6545077708939656\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #quality_metric: host=algo-1, validation binary_classification_accuracy <score>=0.6124529031011496\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #quality_metric: host=algo-1, validation binary_f_1.000 <score>=0.6035087719298246\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #quality_metric: host=algo-1, validation precision <score>=0.6228070175438597\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #quality_metric: host=algo-1, validation recall <score>=0.5853705301505129\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #quality_metric: host=algo-1, validation roc_auc_score <score>=0.6552816431395969\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #quality_metric: host=algo-1, validation binary_balanced_accuracy <score>=0.5\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] #quality_metric: host=algo-1, validation binary_log_loss <score>=0.7045713287604352\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] Best model found for hyperparameters: {\"optimizer\": \"adam\", \"learning_rate\": 0.2056981137054709, \"l1\": 0.20082452777595738, \"wd\": 0.10565041525629222, \"lr_scheduler_step\": 10, \"lr_scheduler_factor\": 0.99, \"lr_scheduler_minimum_lr\": 1e-05}\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] Saved checkpoint to \"/tmp/tmpjy0x89sh/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:26:17 INFO 140250267572032] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641331573.7472534, \"EndTime\": 1641331577.7317386, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 191.8942928314209, \"count\": 1, \"min\": 191.8942928314209, \"max\": 191.8942928314209}, \"epochs\": {\"sum\": 15.0, \"count\": 1, \"min\": 15, \"max\": 15}, \"check_early_stopping.time\": {\"sum\": 16.265392303466797, \"count\": 16, \"min\": 0.8535385131835938, \"max\": 1.561880111694336}, \"update.time\": {\"sum\": 3504.8863887786865, \"count\": 15, \"min\": 199.0211009979248, \"max\": 279.21032905578613}, \"finalize.time\": {\"sum\": 205.58810234069824, \"count\": 1, \"min\": 205.58810234069824, \"max\": 205.58810234069824}, \"setuptime\": {\"sum\": 26.86285972595215, \"count\": 1, \"min\": 26.86285972595215, \"max\": 26.86285972595215}, \"totaltime\": {\"sum\": 4224.642276763916, \"count\": 1, \"min\": 4224.642276763916, \"max\": 4224.642276763916}}}\u001b[0m\n",
      "Training seconds: 82\n",
      "Billable seconds: 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "Using already existing model: linear-learner-220104-2108-012-2611030e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:58:27 INFO 140196092274496] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:58:27 INFO 140196092274496] loading entry points\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:58:27 INFO 140196092274496] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:58:27 INFO 140196092274496] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:58:27 INFO 140196092274496] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:58:27 INFO 140196092274496] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:58:27 INFO 140196092274496] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:58:27 INFO 140196092274496] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:58:27 INFO 140196092274496] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:58:27 INFO 140196092274496] loaded response encoder text/csv\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:58:27 INFO 140196092274496] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:58:27 INFO 140196092274496] Number of server workers: 4\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:58:27 INFO 140196092274496] loading model...\u001b[0m\n",
      "\u001b[34m[01/04/2022 21:58:27 INFO 140196092274496] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:58:27 +0000] [1] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:58:27 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:58:27 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:58:27 +0000] [61] [INFO] Booting worker with pid: 61\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:58:28 +0000] [70] [INFO] Booting worker with pid: 70\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:58:28 +0000] [79] [INFO] Booting worker with pid: 79\u001b[0m\n",
      "\u001b[34m[2022-01-04 21:58:28 +0000] [88] [INFO] Booting worker with pid: 88\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641333507.9302769, \"EndTime\": 1641333509.4038296, \"Dimensions\": {\"Algorithm\": \"LinearLearnerModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641333507.9302769, \"EndTime\": 1641333510.0010076, \"Dimensions\": {\"Algorithm\": \"LinearLearnerModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"json.encoder.time\": {\"sum\": 2.8514862060546875, \"count\": 1, \"min\": 2.8514862060546875, \"max\": 2.8514862060546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1641333507.9302769, \"EndTime\": 1641333510.8367543, \"Dimensions\": {\"Algorithm\": \"LinearLearnerModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"json.encoder.time\": {\"sum\": 63.73119354248047, \"count\": 1, \"min\": 63.73119354248047, \"max\": 63.73119354248047}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[32m2022-01-04T21:58:29.409:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Create a new estimator object using the \"best training job\" ##\n",
    "lin_best = sagemaker.estimator.Estimator.attach(lin_hyperparameter_tuner.best_training_job())\n",
    "\n",
    "## Create a batch transform job and point to s3 training data location ##\n",
    "lin_transformer = lin_best.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')\n",
    "lin_transformer.transform(test_location, content_type='text/csv', split_type='Line')\n",
    "lin_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "621bb687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-345989147144/linear-learner-220104-2108-012-2611030e-2022-01-04-21-52-44-276/test.csv.out to data/linreg_results/test.csv.out\n"
     ]
    }
   ],
   "source": [
    "## Download tranform output from s3 location ##\n",
    "!aws s3 cp --recursive $lin_transformer.output_path $data_dir/linreg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "483da8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinLearner test accuracy: 0.6038706754263892\n",
      "LinLearner test auc: 0.6467501458732036\n"
     ]
    }
   ],
   "source": [
    "## Calculate test accuracy and auc performance ##\n",
    "results = pd.read_csv(os.path.join(data_dir, 'linreg_results/test.csv.out'), header=None)\n",
    "predictions = [int(p.split(':')[1]) for p in results[0]]\n",
    "probs = [float(p.split(':')[1].split('}')[0]) for p in results[1]]\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print ('LinLearner test accuracy: {}'.format(accuracy_score(y_test, predictions)))\n",
    "print ('LinLearner test auc: {}'.format(roc_auc_score(y_test, probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86483be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
